{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>car_class</th>\n",
       "      <th>range</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>max_power</th>\n",
       "      <th>grbx_type_ratios</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "      <th>urb_cons</th>\n",
       "      <th>exturb_cons</th>\n",
       "      <th>overall_cons</th>\n",
       "      <th>co</th>\n",
       "      <th>hc</th>\n",
       "      <th>nox</th>\n",
       "      <th>hcnox</th>\n",
       "      <th>ptcl</th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>COMBI 110 CDI</td>\n",
       "      <td>MINIBUS</td>\n",
       "      <td>MOY-INFER</td>\n",
       "      <td>GO</td>\n",
       "      <td>non</td>\n",
       "      <td>70.0</td>\n",
       "      <td>M 6</td>\n",
       "      <td>1976</td>\n",
       "      <td>2075</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.001</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>VIANO 2.0 CDI</td>\n",
       "      <td>MINIBUS</td>\n",
       "      <td>MOY-SUPER</td>\n",
       "      <td>GO</td>\n",
       "      <td>non</td>\n",
       "      <td>100.0</td>\n",
       "      <td>A 5</td>\n",
       "      <td>2186</td>\n",
       "      <td>2355</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.001</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>SPRINTER COMBI 319 CDI</td>\n",
       "      <td>MINIBUS</td>\n",
       "      <td>MOY-INFER</td>\n",
       "      <td>GO</td>\n",
       "      <td>non</td>\n",
       "      <td>140.0</td>\n",
       "      <td>A 5</td>\n",
       "      <td>2586</td>\n",
       "      <td>2869</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RENAULT</td>\n",
       "      <td>MEGANE Coupé EnergyTCe (115ch) eco2</td>\n",
       "      <td>COUPE</td>\n",
       "      <td>MOY-INFER</td>\n",
       "      <td>ES</td>\n",
       "      <td>non</td>\n",
       "      <td>85.0</td>\n",
       "      <td>M 6</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MERCEDES</td>\n",
       "      <td>COMBI 116 CDI</td>\n",
       "      <td>MINIBUS</td>\n",
       "      <td>MOY-INFER</td>\n",
       "      <td>GO</td>\n",
       "      <td>non</td>\n",
       "      <td>120.0</td>\n",
       "      <td>A 5</td>\n",
       "      <td>2356</td>\n",
       "      <td>2450</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.001</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     brand                                model car_class      range  \\\n",
       "0   0  MERCEDES                        COMBI 110 CDI   MINIBUS  MOY-INFER   \n",
       "1   1  MERCEDES                        VIANO 2.0 CDI   MINIBUS  MOY-SUPER   \n",
       "2   2  MERCEDES               SPRINTER COMBI 319 CDI   MINIBUS  MOY-INFER   \n",
       "3   3   RENAULT  MEGANE Coupé EnergyTCe (115ch) eco2     COUPE  MOY-INFER   \n",
       "4   4  MERCEDES                        COMBI 116 CDI   MINIBUS  MOY-INFER   \n",
       "\n",
       "  fuel_type hybrid  max_power grbx_type_ratios  weight_min  weight_max  \\\n",
       "0        GO    non       70.0              M 6        1976        2075   \n",
       "1        GO    non      100.0              A 5        2186        2355   \n",
       "2        GO    non      140.0              A 5        2586        2869   \n",
       "3        ES    non       85.0              M 6        1280        1280   \n",
       "4        GO    non      120.0              A 5        2356        2450   \n",
       "\n",
       "   urb_cons  exturb_cons  overall_cons     co     hc    nox  hcnox   ptcl  co2  \n",
       "0       9.1          6.4           7.4  0.083    NaN  0.229  0.250  0.001  195  \n",
       "1      10.2          7.0           8.2  0.078    NaN  0.224  0.233  0.001  216  \n",
       "2      12.5          9.0          10.3  0.067  0.014  1.846    NaN  0.002  272  \n",
       "3       6.4          4.6           5.3  0.167  0.039  0.039    NaN  0.001  119  \n",
       "4      10.1          6.9           8.1  0.042    NaN  0.190  0.201  0.001  214  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chargement des données:\n",
    "\"\"\"\n",
    "sample_df = pd.read_csv('sample_submission.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>car_class</th>\n",
       "      <th>range</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>max_power</th>\n",
       "      <th>grbx_type_ratios</th>\n",
       "      <th>weight_min</th>\n",
       "      <th>weight_max</th>\n",
       "      <th>urb_cons</th>\n",
       "      <th>exturb_cons</th>\n",
       "      <th>overall_cons</th>\n",
       "      <th>co</th>\n",
       "      <th>hc</th>\n",
       "      <th>nox</th>\n",
       "      <th>hcnox</th>\n",
       "      <th>ptcl</th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1355</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.081731</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.431687</td>\n",
       "      <td>-0.631726</td>\n",
       "      <td>-0.226086</td>\n",
       "      <td>-0.317102</td>\n",
       "      <td>-0.262405</td>\n",
       "      <td>-0.675586</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>-0.170442</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3608</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.419216</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283067</td>\n",
       "      <td>0.029746</td>\n",
       "      <td>0.302808</td>\n",
       "      <td>0.262172</td>\n",
       "      <td>0.317850</td>\n",
       "      <td>-0.710046</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>-0.182388</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3282</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.644503</td>\n",
       "      <td>1.244019</td>\n",
       "      <td>1.408676</td>\n",
       "      <td>2.193088</td>\n",
       "      <td>1.841020</td>\n",
       "      <td>-0.785857</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>3.693046</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>1.138173</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2325</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750474</td>\n",
       "      <td>10</td>\n",
       "      <td>-2.800586</td>\n",
       "      <td>-2.509832</td>\n",
       "      <td>-1.524279</td>\n",
       "      <td>-2.054927</td>\n",
       "      <td>-1.785574</td>\n",
       "      <td>-0.096663</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>-0.624407</td>\n",
       "      <td>0.233684</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1358</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861677</td>\n",
       "      <td>0.254174</td>\n",
       "      <td>0.254727</td>\n",
       "      <td>0.165626</td>\n",
       "      <td>0.245319</td>\n",
       "      <td>-0.958156</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>-0.263624</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  brand  model  car_class  range  fuel_type  hybrid  max_power  \\\n",
       "0   0     26   1355          6      3         10       0  -1.081731   \n",
       "1   1     26   3608          6      5         10       0  -0.419216   \n",
       "2   2     26   3282          6      3         10       0   0.464137   \n",
       "3   3     33   2325          5      3          2       0  -0.750474   \n",
       "4   4     26   1358          6      3         10       0   0.022460   \n",
       "\n",
       "   grbx_type_ratios  weight_min  weight_max  urb_cons  exturb_cons  \\\n",
       "0                10   -0.431687   -0.631726 -0.226086    -0.317102   \n",
       "1                 1    0.283067    0.029746  0.302808     0.262172   \n",
       "2                 1    1.644503    1.244019  1.408676     2.193088   \n",
       "3                10   -2.800586   -2.509832 -1.524279    -2.054927   \n",
       "4                 1    0.861677    0.254174  0.254727     0.165626   \n",
       "\n",
       "   overall_cons        co        hc       nox     hcnox      ptcl  co2  \n",
       "0     -0.262405 -0.675586  0.026455 -0.170442  0.250000  0.107472  195  \n",
       "1      0.317850 -0.710046  0.026455 -0.182388  0.233000  0.107472  216  \n",
       "2      1.841020 -0.785857  0.014000  3.693046  0.233684  1.138173  272  \n",
       "3     -1.785574 -0.096663  0.039000 -0.624407  0.233684  0.107472  119  \n",
       "4      0.245319 -0.958156  0.026455 -0.263624  0.201000  0.107472  214  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gestion des nan:\n",
    "\"\"\"\n",
    "\n",
    "# Identification des colonnes avec au moins un NaN dans train_df\n",
    "colonnes_avec_nan = test_df.columns[test_df.isna().any()].tolist()\n",
    "train_df[colonnes_avec_nan] = train_df[colonnes_avec_nan].fillna(train_df[colonnes_avec_nan].mean())\n",
    "test_df[colonnes_avec_nan] = test_df[colonnes_avec_nan].fillna(test_df[colonnes_avec_nan].mean())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Probleme avec les strings (LabelEncoder):\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "colonnes_string = ['brand', 'model', 'car_class', 'fuel_type', 'hybrid', 'grbx_type_ratios', 'range']\n",
    "\n",
    "# Conversion des colonnes en type 'category'\n",
    "for colonne in colonnes_string:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(pd.concat([train_df[colonne], test_df[colonne]]))\n",
    "    train_df[colonne] = le.transform(train_df[colonne])\n",
    "    test_df[colonne] = le.transform(test_df[colonne])\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Normalisation des données:\n",
    "\"\"\"\n",
    "numeric_colons = ['max_power', 'weight_min', 'weight_max', 'urb_cons', 'exturb_cons', 'overall_cons', 'co', 'nox', 'ptcl']\n",
    "scaler = StandardScaler()\n",
    "train_df[numeric_colons] = scaler.fit_transform(train_df[numeric_colons])\n",
    "test_df[numeric_colons] = scaler.transform(test_df[numeric_colons])\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Jeu de données:\n",
    "\"\"\"\n",
    "X_train = train_df[[col for col in train_df.columns if col != 'co2' and col != 'id']]\n",
    "Y_train = train_df['co2']\n",
    "\n",
    "X_test = test_df[[col for col in test_df.columns if col != 'id']]\n",
    "id_test = test_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luc/INSA/4IF/ML/4IF_ML_TP1/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 40411.7193, Val Loss: 35985.1706\n",
      "Epoch 2/100, Train Loss: 35051.2181, Val Loss: 25754.6268\n",
      "Epoch 3/100, Train Loss: 26760.2766, Val Loss: 22382.8815\n",
      "Epoch 4/100, Train Loss: 17305.3764, Val Loss: 11172.5017\n",
      "Epoch 5/100, Train Loss: 9239.1603, Val Loss: 2437.5294\n",
      "Epoch 6/100, Train Loss: 3942.5832, Val Loss: 3621.3545\n",
      "Epoch 7/100, Train Loss: 1286.0781, Val Loss: 443.7314\n",
      "Epoch 8/100, Train Loss: 345.0432, Val Loss: 263.5792\n",
      "Epoch 9/100, Train Loss: 117.9364, Val Loss: 724.9064\n",
      "Epoch 10/100, Train Loss: 73.9666, Val Loss: 553.0291\n",
      "Epoch 11/100, Train Loss: 70.2136, Val Loss: 75.3806\n",
      "Epoch 12/100, Train Loss: 63.9276, Val Loss: 90.9578\n",
      "Epoch 13/100, Train Loss: 67.6891, Val Loss: 299.5958\n",
      "Epoch 14/100, Train Loss: 65.4787, Val Loss: 124.3691\n",
      "Epoch 15/100, Train Loss: 63.7484, Val Loss: 194.7418\n",
      "Epoch 16/100, Train Loss: 66.2151, Val Loss: 1940.9468\n",
      "Epoch 17/100, Train Loss: 61.4348, Val Loss: 133.7375\n",
      "Epoch 18/100, Train Loss: 57.3240, Val Loss: 402.3869\n",
      "Epoch 19/100, Train Loss: 56.7354, Val Loss: 4232.3032\n",
      "Epoch 20/100, Train Loss: 58.2951, Val Loss: 109.9071\n",
      "Epoch 21/100, Train Loss: 55.5576, Val Loss: 65.2984\n",
      "Epoch 22/100, Train Loss: 54.5218, Val Loss: 82.4014\n",
      "Epoch 23/100, Train Loss: 51.8416, Val Loss: 1222.5116\n",
      "Epoch 24/100, Train Loss: 54.3536, Val Loss: 98.2922\n",
      "Epoch 25/100, Train Loss: 51.9856, Val Loss: 129.5192\n",
      "Epoch 26/100, Train Loss: 52.9055, Val Loss: 103.1874\n",
      "Epoch 27/100, Train Loss: 51.8543, Val Loss: 81.1160\n",
      "Epoch 28/100, Train Loss: 47.8268, Val Loss: 1007.7384\n",
      "Epoch 29/100, Train Loss: 49.0341, Val Loss: 69.9904\n",
      "Epoch 30/100, Train Loss: 49.0100, Val Loss: 4015.5575\n",
      "Epoch 31/100, Train Loss: 45.5277, Val Loss: 6364.6710\n",
      "Epoch 32/100, Train Loss: 49.7722, Val Loss: 78.9031\n",
      "Epoch 33/100, Train Loss: 48.6952, Val Loss: 1112.9413\n",
      "Epoch 34/100, Train Loss: 45.4596, Val Loss: 105.9374\n",
      "Epoch 35/100, Train Loss: 48.2944, Val Loss: 120.1259\n",
      "Epoch 36/100, Train Loss: 46.6517, Val Loss: 3403.0953\n",
      "Early stopping après 36 epochs sans amélioration.\n",
      "Validation MAE: 5.4535\n",
      "Validation R²: -2.1557\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Réseau de neurones avec PyTorch pour la régression:\n",
    "\"\"\"\n",
    "# Installation si nécessaire\n",
    "# !pip install torch scikit-learn numpy matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Vérifier si CUDA est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de: {device}\")\n",
    "\n",
    "# Créer un dataset PyTorch personnalisé\n",
    "class CO2Dataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        \n",
    "        if y is not None:\n",
    "            self.y = torch.tensor(y.values, dtype=torch.float32).reshape(-1, 1)\n",
    "            self.has_target = True\n",
    "        else:\n",
    "            self.has_target = False\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.has_target:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]\n",
    "\n",
    "# Définition du modèle de réseau de neurones\n",
    "class CO2RegressionNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CO2RegressionNet, self).__init__()\n",
    "        \n",
    "        # Architecture du réseau\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de validation\n",
    "X_train_nn, X_val, y_train_nn, y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Création des datasets et dataloaders\n",
    "train_dataset = CO2Dataset(X_train_nn, y_train_nn)\n",
    "val_dataset = CO2Dataset(X_val, y_val)\n",
    "test_dataset = CO2Dataset(X_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Initialisation du modèle, fonction de perte et optimiseur\n",
    "input_dim = X_train.shape[1]\n",
    "model = CO2RegressionNet(input_dim).to(device)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error pour la régression\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100, early_stopping_patience=15):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Mode entraînement\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # Remise à zéro des gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass et optimisation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # Mode évaluation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        # Ajustement du learning rate\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Affichage des métriques\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n",
    "        \n",
    "        # Sauvegarde du meilleur modèle\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if no_improve_epochs >= early_stopping_patience:\n",
    "            print(f'Early stopping après {epoch+1} epochs sans amélioration.')\n",
    "            break\n",
    "    \n",
    "    # Chargement du meilleur modèle\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Entraînement du modèle\n",
    "trained_model, train_losses, val_losses = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100, early_stopping_patience=15\n",
    ")\n",
    "\n",
    "# Graphique des pertes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Courbes d\\'apprentissage')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('nn_training_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Évaluation sur l'ensemble de validation\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        val_predictions.extend(outputs.cpu().numpy())\n",
    "        val_targets.extend(y_batch.numpy())\n",
    "\n",
    "val_predictions = np.array(val_predictions).flatten()\n",
    "val_targets = np.array(val_targets).flatten()\n",
    "\n",
    "val_mae = mean_absolute_error(val_targets, val_predictions)\n",
    "val_r2 = r2_score(val_targets, val_predictions)\n",
    "\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "print(f\"Validation R²: {val_r2:.4f}\")\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        test_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "Y_test_nn = np.array(test_predictions).flatten()\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "resultat = [(id_test[i], Y_test_nn[i]) for i in range(len(Y_test_nn))]\n",
    "with open('resultat_pytorch.csv', 'w') as f:\n",
    "    f.write(\"id,co2\\n\")\n",
    "    for id, co2 in resultat:\n",
    "        f.write(f\"{id},{int(round(co2))}\\n\")\n",
    "\n",
    "# Comparaison des prédictions du modèle PyTorch avec le modèle original\n",
    "if 'model' in globals() and hasattr(model, 'predict'):\n",
    "    Y_pred_original = model.predict(X_val.values)\n",
    "    mae_original = mean_absolute_error(y_val, Y_pred_original)\n",
    "    r2_original = r2_score(y_val, Y_pred_original)\n",
    "    \n",
    "    print(\"\\nComparaison avec le modèle original:\")\n",
    "    print(f\"MAE original: {mae_original:.4f}, R² original: {r2_original:.4f}\")\n",
    "    print(f\"MAE PyTorch: {val_mae:.4f}, R² PyTorch: {val_r2:.4f}\")\n",
    "    \n",
    "    # Amélioration en pourcentage\n",
    "    if mae_original > 0:\n",
    "        mae_improvement = ((mae_original - val_mae) / mae_original) * 100\n",
    "        print(f\"Amélioration MAE: {mae_improvement:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
